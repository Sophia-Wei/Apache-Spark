{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In case you want to learn how ETL is done, please run the following notebook first and update the file name below accordingly\n\nhttps://github.com/IBM/coursera/blob/master/coursera_ml/a2_w1_s3_ETL.ipynb"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20191128124910-0000\nKERNEL_ID = d77e6a47-aac5-419c-a127-01ed22c84b9a\n--2019-11-28 12:49:13--  https://github.com/IBM/coursera/raw/master/hmp.parquet\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/IBM/coursera/master/hmp.parquet [following]\n--2019-11-28 12:49:13--  https://raw.githubusercontent.com/IBM/coursera/master/hmp.parquet\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 932997 (911K) [application/octet-stream]\nSaving to: 'hmp.parquet'\n\n100%[======================================>] 932,997     --.-K/s   in 0.04s   \n\n2019-11-28 12:49:13 (22.2 MB/s) - 'hmp.parquet' saved [932997/932997]\n\n"
                }
            ],
            "source": "# delete files from previous runs\n!rm -f hmp.parquet*\n\n# download the file containing the data in PARQUET format\n!wget https://github.com/IBM/coursera/raw/master/hmp.parquet\n    \n# create a dataframe out of it\ndf = spark.read.parquet('hmp.parquet')\n\n# register a corresponding query table\ndf.createOrReplaceTempView('df')"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "pixiedust": {
                    "displayParams": {}
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+---+---+--------------------+-----------+----------+\n|  x|  y|  z|              source|      class|classIndex|\n+---+---+---+--------------------+-----------+----------+\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|\n| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|\n| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|\n| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|\n| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|\n+---+---+---+--------------------+-----------+----------+\nonly showing top 20 rows\n\n+----------+\n|classIndex|\n+----------+\n|       8.0|\n|       0.0|\n|       7.0|\n|       1.0|\n|       4.0|\n|      11.0|\n|       3.0|\n|       2.0|\n|      10.0|\n|      13.0|\n|       6.0|\n|       5.0|\n|       9.0|\n|      12.0|\n+----------+\n\n"
                }
            ],
            "source": "from pyspark.ml.feature import StringIndexer\n\n\nindexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\nindexed = indexer.fit(df).transform(df)\nindexed.show()\nindexed.select('classIndex').distinct().show()"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "pixiedust": {
                    "displayParams": {
                        "handlerId": "tableView"
                    }
                }
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+---+---+--------------------+-----------+----------+--------------+\n|  x|  y|  z|              source|      class|classIndex|   categoryVec|\n+---+---+---+--------------------+-----------+----------+--------------+\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|\n+---+---+---+--------------------+-----------+----------+--------------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n\n\nencoder = OneHotEncoder(inputCol=\"classIndex\", outputCol=\"categoryVec\")\nencoded = encoder.transform(indexed)\nencoded.show()\n"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+---+---+--------------------+-----------+----------+--------------+----------------+\n|  x|  y|  z|              source|      class|classIndex|   categoryVec|        features|\n+---+---+---+--------------------+-----------+----------+--------------+----------------+\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|\n| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|\n| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|\n| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|\n| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|\n| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|\n| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|\n| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|\n| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|\n| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|\n| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|\n| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|\n| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|\n| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|\n| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|\n+---+---+---+--------------------+-----------+----------+--------------+----------------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "from pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorAssembler\n\nvectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n                                  outputCol=\"features\")\n\n# For your special case that has string instead of doubles you should cast them first.\n# expr = [col(c).cast(\"Double\").alias(c) \n#         for c in vectorAssembler.getInputCols()]\n\n# df2 = df2.select(*expr)\nfeatures_vectorized = vectorAssembler.transform(encoded)\nfeatures_vectorized.show()"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n|  x|  y|  z|              source|      class|classIndex|   categoryVec|        features|       features_norm|\n+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|\n| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|\n| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|\n| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|\n| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|\n| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|\n| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|\n| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|\n| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|\n| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|\n| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|\n| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|\n| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|\n| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|\n| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|\n+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "from pyspark.ml.feature import Normalizer\nfrom pyspark.ml.linalg import Vectors\n\nnormalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\nl1NormData = normalizer.transform(features_vectorized)\nl1NormData.show()\n\n"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "df_train = l1NormData.drop(\"source\").drop(\"class\").drop(\"classIndex\").drop(\"features\").drop(\"x\").drop(\"y\").drop(\"z\")"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+--------------+--------------------+\n|   categoryVec|       features_norm|\n+--------------+--------------------+\n|(13,[6],[1.0])|[0.20754716981132...|\n|(13,[6],[1.0])|[0.20754716981132...|\n|(13,[6],[1.0])|[0.20183486238532...|\n|(13,[6],[1.0])|[0.20183486238532...|\n|(13,[6],[1.0])|[0.19626168224299...|\n|(13,[6],[1.0])|[0.20560747663551...|\n|(13,[6],[1.0])|[0.19047619047619...|\n|(13,[6],[1.0])|[0.20370370370370...|\n|(13,[6],[1.0])|[0.20754716981132...|\n|(13,[6],[1.0])|[0.20370370370370...|\n|(13,[6],[1.0])|[0.2,0.4857142857...|\n|(13,[6],[1.0])|[0.19230769230769...|\n|(13,[6],[1.0])|[0.20388349514563...|\n|(13,[6],[1.0])|[0.20388349514563...|\n|(13,[6],[1.0])|[0.18867924528301...|\n|(13,[6],[1.0])|[0.17821782178217...|\n|(13,[6],[1.0])|[0.18811881188118...|\n|(13,[6],[1.0])|[0.15533980582524...|\n|(13,[6],[1.0])|[0.17142857142857...|\n|(13,[6],[1.0])|[0.17821782178217...|\n+--------------+--------------------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "df_train.show()"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "from pyspark.ml import Pipeline\npipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer])\nmodel = pipeline.fit(df)\nprediction = model.transform(df)"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n|  x|  y|  z|              source|      class|classIndex|   categoryVec|        features|       features_norm|\n+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|\n| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|\n| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|\n| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|\n| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|\n| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|\n| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|\n| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|\n| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|\n| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|\n| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|\n| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|\n| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|\n| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|\n| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|\n| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|\n| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|\n| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|\n+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\nonly showing top 20 rows\n\n"
                }
            ],
            "source": "prediction.show()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}